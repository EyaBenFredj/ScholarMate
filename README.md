
# ğŸ“š ScholarMate â€“ AI Research Paper Assistant

ScholarMate is an open-source, locally-running GenAI assistant that helps you **understand, analyze, and interact with research papers** using state-of-the-art language models, semantic search, and document parsing â€” all **100% free and private**.

> ğŸ§  Ask questions, get summaries, extract tables, generate flashcards â€” all from your own PDF research papers, with no paid API keys or cloud dependencies.

---

## ğŸ¯ Features

âœ… Upload any PDF research paper  
âœ… Ask questions using RAG (retrieval-augmented generation)  
âœ… Summarize entire sections (Abstract, Methods, Results, etc.)  
âœ… ELI5 Mode: "Explain Like Iâ€™m 5" for simpler answers  
âœ… Generate highlights and key insights  
âœ… Create study flashcards (Q&A style)  
âœ… Explain citations and references  
âœ… Extract tables from PDF automatically  
âœ… Compare two papers (similarity, methods, conclusions)  
âœ… View full Q&A chat history  
âœ… Fully offline â€“ powered by [Ollama](https://ollama.com/) + FAISS + Streamlit

---

## ğŸ§± Project Structure

```

ScholarMate/
â”œâ”€â”€ app.py              # Streamlit app (main UI)
â”œâ”€â”€ pdf\_utils.py        # PDF parsing: text, sections, tables
â”œâ”€â”€ rag\_pipeline.py     # Embedding, RAG, summarization, flashcards, etc.
â”œâ”€â”€ requirements.txt    # Python dependencies

````

---

## ğŸ› ï¸ Tech Stack

| Layer         | Tool / Library                                      |
|---------------|-----------------------------------------------------|
| ğŸ§  LLM         | [LLaMA3](https://ollama.com/library/llama3) via [Ollama](https://ollama.com) |
| ğŸ” Embeddings  | SentenceTransformers (MiniLM)                       |
| ğŸ“¦ Vector DB   | FAISS (local, fast, open-source)                    |
| ğŸ“„ PDF Parsing | PyMuPDF + pdfplumber                                |
| ğŸ’¬ UI          | Streamlit                                           |
| ğŸ§  RAG Logic   | LangChain + custom prompt design                    |

---

## ğŸš€ Installation Guide (Windows / Linux / macOS)

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/ScholarMate.git
cd ScholarMate
````

### 2. Set Up Python Environment

```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install and Start Ollama (Local LLM)

* Download and install [Ollama](https://ollama.com)
* Pull a model:

```bash
ollama pull llama3
```

* Run the model:

```bash
ollama run llama3
```

> ğŸ“ Leave that terminal open â€“ it runs your LLM backend locally.

### 5. Run ScholarMate

In a **separate terminal** (with virtual environment activated):

```bash
streamlit run app.py
```

Then open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ğŸ§ª Usage Examples

* `"Summarize the abstract"`
* `"What is the main contribution of the paper?"`
* `"Explain the method section like I'm 5"`
* `"List key findings"`
* `"Create flashcards for this paper"`
* `"Compare this paper with another one"`
* `"Extract tables with results"`

