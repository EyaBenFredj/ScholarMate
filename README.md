# ğŸ“š ScholarMate â€“ AI Research Paper Assistant

ScholarMate is an open-source, locally-running GenAI assistant that helps you **understand, analyze, and interact with research papers** using state-of-the-art language models, semantic search, and document parsing â€” all **100% free and private**.

> ğŸ§  Ask questions, get summaries, extract tables, generate flashcards â€” all from your own PDF research papers, with no paid API keys or cloud dependencies.

---

## ğŸ¯ Features

âœ… Upload any PDF research paper  
âœ… Ask questions using RAG (retrieval-augmented generation)  
âœ… Summarize entire sections (Abstract, Methods, Results, etc.)  
âœ… ELI5 Mode: "Explain Like Iâ€™m 5" for simpler answers  
âœ… Generate highlights and key insights  
âœ… Create study flashcards (Q&A style)  
âœ… Explain citations and references  
âœ… Extract tables from PDF automatically  
âœ… Compare two papers (similarity, methods, conclusions)  
âœ… View full Q&A chat history  
âœ… Fully offline â€“ powered by [Ollama](https://ollama.com/) + FAISS + Streamlit

---

## ğŸ§± Project Structure

ScholarMate/
â”œâ”€â”€ app.py # Streamlit app (main UI)
â”œâ”€â”€ pdf_utils.py # PDF parsing: text, sections, tables
â”œâ”€â”€ rag_pipeline.py # Embedding, RAG, summarization, flashcards, etc.
â”œâ”€â”€ requirements.txt # Python dependencies

yaml
Copier le code

---

## ğŸ› ï¸ Tech Stack

| Layer         | Tool / Library                      |
|---------------|-------------------------------------|
| ğŸ§  LLM         | [LLaMA3](https://ollama.com/library/llama3) via [Ollama](https://ollama.com) |
| ğŸ” Embeddings  | SentenceTransformers (MiniLM)       |
| ğŸ“¦ Vector DB   | FAISS (local, fast, open-source)    |
| ğŸ“„ PDF Parsing | PyMuPDF + pdfplumber                |
| ğŸ’¬ UI          | Streamlit                           |
| ğŸ§  RAG Logic   | LangChain + custom prompt design     |

---

## ğŸš€ Installation Guide (Windows / Linux / macOS)

### 1. Clone the Repo

```bash
git clone https://github.com/yourusername/ScholarMate.git
cd ScholarMate
2. Set Up Python Environment
bash
Copier le code
python -m venv venv
venv\Scripts\activate  # or source venv/bin/activate on macOS/Linux
3. Install Dependencies
bash
Copier le code
pip install -r requirements.txt
4. Install and Start Ollama (Local LLM)
Download and install Ollama

Pull a model:

bash
Copier le code
ollama pull llama3
Run the model:

bash
Copier le code
ollama run llama3
Leave that terminal open â€“ it runs your LLM backend locally.

5. Run ScholarMate
In a separate terminal (with virtual env activated):

bash
Copier le code
streamlit run app.py
Open http://localhost:8501 in your browser.

ğŸ§ª Usage Examples
"Summarize the abstract"

"What is the main contribution of the paper?"

"Explain the method section like I'm 5"

"List key findings"

"Create flashcards for this paper"

"Compare this paper with another one"

"Extract tables with results"

ğŸ›¡ï¸ Privacy & Cost
ğŸ’° Free forever â€“ no OpenAI or cloud API keys required

ğŸ”’ 100% private â€“ runs entirely on your device

ğŸ“¶ Offline-capable â€“ LLM inference and vector search are local

ğŸ“Œ Roadmap
 Export chat history as PDF / Markdown

 Summarize citations with links to external databases

 Add Whisper or voice interface for spoken Q&A

 Deploy to Hugging Face Spaces (optional cloud demo)

ğŸ™Œ Contributing
This is an open project!
Feel free to:

Suggest new features

Improve prompts

Add better section detection

Help with UI polish or deployment

ğŸ“„ License
MIT License â€“ feel free to use and adapt.

âœ¨ Credits
LLaMA 3 by Meta

Ollama â€“ local LLM runner

LangChain â€“ RAG pipeline framework

SentenceTransformers â€“ powerful open-source embeddings

Streamlit â€“ fast ML app UI

ğŸ’¬ Contact / Feedback
Built by [Your Name]
Find me on LinkedIn or GitHub

yaml
Copier le code

---

âœ… You can now paste this directly into your `README.md`.  
Let me know if you want help:
- Replacing your name and links
- Deploying it online
- Writing a LinkedIn post or GitHub release

Youâ€™ve got something special here.
